{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as q\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_KEY = \"D6427ILDPCC3RZCA\"\n",
    "\n",
    "def _api_call(symbol, candle=\"5min\", output_size=\"compact\"):\n",
    "    url = \"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={stock}&interval={skip}&apikey={key}&outputsize={output_size}\".format(\n",
    "        stock=symbol, skip=candle, key=API_KEY, output_size=output_size\n",
    "    )\n",
    "    print(\"API::%s\" % url)\n",
    "    s = q.get(url)\n",
    "    return s.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API::https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=AMZN&interval=1min&apikey=D6427ILDPCC3RZCA&outputsize=full\n",
      "{'1. Information': 'Intraday (1min) prices and volumes', '2. Symbol': 'AMZN', '3. Last Refreshed': '2018-02-05 16:00:00', '4. Interval': '1min', '5. Output Size': 'Full size', '6. Time Zone': 'US/Eastern'}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "d = _api_call('AMZN', candle=\"1min\", output_size=\"full\")\n",
    "print(d['Meta Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3910"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get time series\n",
    "ts = d['Time Series (1min)']\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'close': 1390.0,\n",
       " 'high': 1399.0,\n",
       " 'low': 1388.81,\n",
       " 'open': 1398.47,\n",
       " 'volume': 38048.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_data(ts):\n",
    "    ts = list(ts.items())\n",
    "    data = []\n",
    "    for _, v in ts:\n",
    "        v = v.items()\n",
    "        data.append({key[3:]: float(val) for key, val in v})\n",
    "    return data\n",
    "            \n",
    "data = prep_data(ts)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382.7733333333333,\n",
       " 1388.0366666666666,\n",
       " 1392.0433333333333,\n",
       " 1397.3066666666666,\n",
       " 1401.3133333333333,\n",
       " 1406.5766666666666,\n",
       " 1410.5833333333333)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_pivots(p):\n",
    "    pp = (p['high'] + p['low'] + p['close']) / 3\n",
    "    r1 = pp * 2 - p['low']\n",
    "    s1 = pp * 2 - p['high']\n",
    "    r2 = pp + (p['high'] - p['low'])\n",
    "    s2 = pp - (p['high'] - p['low'])\n",
    "    r3 = p['high'] + 2 * (pp - p['low'])\n",
    "    s3 = p['low'] - 2 * (p['high'] - pp)\n",
    "    return s3, s2, s1, pp, r1, r2, r3\n",
    "\n",
    "calc_pivots(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(range(1, len(data)))\n",
    "pivots = []\n",
    "Y = []\n",
    "for ix in range(1, len(data)):\n",
    "    pivots.append(calc_pivots(data[ix-1]))\n",
    "    Y.append(data[ix]['close'])\n",
    "s3, s2, s1, pp, r1, r2, r3 = list(np.array(pivots).T)\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d91210f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, s1, 'r', X, r1, 'b', X, Y, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d91210ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvMbcC9HtfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d8ed2ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "err = [min(abs(y - r1[i]), abs(y - s1[i])) for i, y in enumerate(Y)]\n",
    "\n",
    "plt.plot(X, err, 'r')\n",
    "plt.show()\n",
    "\n",
    "low_err = [e if e < 10 else 0 for e in err]\n",
    "plt.plot(X, low_err, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lambda/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LETS MAKE A FUCKING LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Activation, Dense, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# our input will be the pivot points from the previous candle (7), and formatted to include a timestep\n",
    "model.add(LSTM(1, input_shape=(1, 7), return_sequences=False))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('tanh'))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1488.60666667 1490.59333333 1494.02666667 1496.01333333 1500.95333333\n",
      " 1510.59666667 1525.07333333]\n",
      "(3909, 7)\n",
      "(3909, 1, 7)\n",
      "[[0.56932473 0.50065392 0.45039335 0.34189564 0.35143989 0.36655978\n",
      "  0.35536451]]\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(pivots)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "print(scaler.data_max_)\n",
    "X_train = scaler.transform(X)\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396.05\n",
      "(3909,)\n",
      "(3909,)\n",
      "(3909,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3909, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(Y)\n",
    "print(Y[0])\n",
    "print(Y.shape)\n",
    "Y_r = Y - r1\n",
    "Y_s = Y - s1\n",
    "print(Y_r.shape)\n",
    "print(Y_s.shape)\n",
    "Y_train = np.asarray((Y_r, Y_s)).T\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3127 samples, validate on 782 samples\n",
      "Epoch 1/400\n",
      "3127/3127 [==============================] - 0s 47us/step - loss: 8.3035 - val_loss: 1.5831\n",
      "Epoch 2/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3077 - val_loss: 1.5821\n",
      "Epoch 3/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3083 - val_loss: 1.5833\n",
      "Epoch 4/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3086 - val_loss: 1.5826\n",
      "Epoch 5/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3068 - val_loss: 1.5836\n",
      "Epoch 6/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3087 - val_loss: 1.5828\n",
      "Epoch 7/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3056 - val_loss: 1.5843\n",
      "Epoch 8/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3042 - val_loss: 1.5851\n",
      "Epoch 9/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3041 - val_loss: 1.5840\n",
      "Epoch 10/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3083 - val_loss: 1.5860\n",
      "Epoch 11/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3078 - val_loss: 1.5835\n",
      "Epoch 12/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3042 - val_loss: 1.5846\n",
      "Epoch 13/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3055 - val_loss: 1.5812\n",
      "Epoch 14/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3048 - val_loss: 1.5841\n",
      "Epoch 15/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3045 - val_loss: 1.5832\n",
      "Epoch 16/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3064 - val_loss: 1.5827\n",
      "Epoch 17/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3038 - val_loss: 1.5803\n",
      "Epoch 18/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3010 - val_loss: 1.5806\n",
      "Epoch 19/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3071 - val_loss: 1.5801\n",
      "Epoch 20/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3033 - val_loss: 1.5823\n",
      "Epoch 21/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3073 - val_loss: 1.5849\n",
      "Epoch 22/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3037 - val_loss: 1.5858\n",
      "Epoch 23/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3035 - val_loss: 1.5842\n",
      "Epoch 24/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3041 - val_loss: 1.5827\n",
      "Epoch 25/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3022 - val_loss: 1.5814\n",
      "Epoch 26/400\n",
      "3127/3127 [==============================] - 0s 37us/step - loss: 8.3040 - val_loss: 1.5838\n",
      "Epoch 27/400\n",
      "3127/3127 [==============================] - 0s 39us/step - loss: 8.3049 - val_loss: 1.5820\n",
      "Epoch 28/400\n",
      "3127/3127 [==============================] - 0s 38us/step - loss: 8.2998 - val_loss: 1.5817\n",
      "Epoch 29/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3071 - val_loss: 1.5817\n",
      "Epoch 30/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3053 - val_loss: 1.5828\n",
      "Epoch 31/400\n",
      "3127/3127 [==============================] - 0s 38us/step - loss: 8.3028 - val_loss: 1.5824\n",
      "Epoch 32/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3056 - val_loss: 1.5832\n",
      "Epoch 33/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3014 - val_loss: 1.5832\n",
      "Epoch 34/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3006 - val_loss: 1.5814\n",
      "Epoch 35/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3035 - val_loss: 1.5834\n",
      "Epoch 36/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3026 - val_loss: 1.5845\n",
      "Epoch 37/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3032 - val_loss: 1.5832\n",
      "Epoch 38/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3077 - val_loss: 1.5839\n",
      "Epoch 39/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3048 - val_loss: 1.5822\n",
      "Epoch 40/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3020 - val_loss: 1.5805\n",
      "Epoch 41/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3029 - val_loss: 1.5826\n",
      "Epoch 42/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3025 - val_loss: 1.5825\n",
      "Epoch 43/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3041 - val_loss: 1.5837\n",
      "Epoch 44/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3041 - val_loss: 1.5827\n",
      "Epoch 45/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3007 - val_loss: 1.5823\n",
      "Epoch 46/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3049 - val_loss: 1.5826\n",
      "Epoch 47/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3047 - val_loss: 1.5857\n",
      "Epoch 48/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3005 - val_loss: 1.5824\n",
      "Epoch 49/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3072 - val_loss: 1.5822\n",
      "Epoch 50/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3031 - val_loss: 1.5818\n",
      "Epoch 51/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3021 - val_loss: 1.5825\n",
      "Epoch 52/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3002 - val_loss: 1.5819\n",
      "Epoch 53/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3039 - val_loss: 1.5830\n",
      "Epoch 54/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3044 - val_loss: 1.5829\n",
      "Epoch 55/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3050 - val_loss: 1.5834\n",
      "Epoch 56/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3051 - val_loss: 1.5820\n",
      "Epoch 57/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3026 - val_loss: 1.5841\n",
      "Epoch 58/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3017 - val_loss: 1.5844\n",
      "Epoch 59/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3012 - val_loss: 1.5827\n",
      "Epoch 60/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2985 - val_loss: 1.5840\n",
      "Epoch 61/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3032 - val_loss: 1.5841\n",
      "Epoch 62/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3012 - val_loss: 1.5831\n",
      "Epoch 63/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3030 - val_loss: 1.5832\n",
      "Epoch 64/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3030 - val_loss: 1.5813\n",
      "Epoch 65/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3023 - val_loss: 1.5862\n",
      "Epoch 66/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3003 - val_loss: 1.5848\n",
      "Epoch 67/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3004 - val_loss: 1.5838\n",
      "Epoch 68/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3003 - val_loss: 1.5843\n",
      "Epoch 69/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3027 - val_loss: 1.5818\n",
      "Epoch 70/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3006 - val_loss: 1.5820\n",
      "Epoch 71/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2995 - val_loss: 1.5823\n",
      "Epoch 72/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2982 - val_loss: 1.5826\n",
      "Epoch 73/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3004 - val_loss: 1.5828\n",
      "Epoch 74/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2992 - val_loss: 1.5841\n",
      "Epoch 75/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3017 - val_loss: 1.5845\n",
      "Epoch 76/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3043 - val_loss: 1.5835\n",
      "Epoch 77/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3007 - val_loss: 1.5828\n",
      "Epoch 78/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3023 - val_loss: 1.5845\n",
      "Epoch 79/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3002 - val_loss: 1.5830\n",
      "Epoch 80/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3015 - val_loss: 1.5842\n",
      "Epoch 81/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3012 - val_loss: 1.5831\n",
      "Epoch 82/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2963 - val_loss: 1.5838\n",
      "Epoch 83/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3044 - val_loss: 1.5834\n",
      "Epoch 84/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3051 - val_loss: 1.5821\n",
      "Epoch 85/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3007 - val_loss: 1.5825\n",
      "Epoch 86/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3031 - val_loss: 1.5839\n",
      "Epoch 87/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2996 - val_loss: 1.5829\n",
      "Epoch 88/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3052 - val_loss: 1.5844\n",
      "Epoch 89/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3005 - val_loss: 1.5839\n",
      "Epoch 90/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2999 - val_loss: 1.5843\n",
      "Epoch 91/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3009 - val_loss: 1.5845\n",
      "Epoch 92/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3028 - val_loss: 1.5847\n",
      "Epoch 93/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3022 - val_loss: 1.5842\n",
      "Epoch 94/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3026 - val_loss: 1.5841\n",
      "Epoch 95/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3017 - val_loss: 1.5831\n",
      "Epoch 96/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3009 - val_loss: 1.5845\n",
      "Epoch 97/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3046 - val_loss: 1.5824\n",
      "Epoch 98/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3027 - val_loss: 1.5842\n",
      "Epoch 99/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2982 - val_loss: 1.5841\n",
      "Epoch 100/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3020 - val_loss: 1.5837\n",
      "Epoch 101/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3010 - val_loss: 1.5842\n",
      "Epoch 102/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3007 - val_loss: 1.5848\n",
      "Epoch 103/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2984 - val_loss: 1.5851\n",
      "Epoch 104/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3008 - val_loss: 1.5836\n",
      "Epoch 105/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3008 - val_loss: 1.5837\n",
      "Epoch 106/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2981 - val_loss: 1.5835\n",
      "Epoch 107/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2997 - val_loss: 1.5838\n",
      "Epoch 108/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2972 - val_loss: 1.5841\n",
      "Epoch 109/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2976 - val_loss: 1.5840\n",
      "Epoch 110/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3022 - val_loss: 1.5831\n",
      "Epoch 111/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3000 - val_loss: 1.5832\n",
      "Epoch 112/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3014 - val_loss: 1.5836\n",
      "Epoch 113/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3001 - val_loss: 1.5839\n",
      "Epoch 114/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2982 - val_loss: 1.5847\n",
      "Epoch 115/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3019 - val_loss: 1.5840\n",
      "Epoch 116/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2972 - val_loss: 1.5841\n",
      "Epoch 117/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2954 - val_loss: 1.5816\n",
      "Epoch 118/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3003 - val_loss: 1.5850\n",
      "Epoch 119/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2966 - val_loss: 1.5833\n",
      "Epoch 120/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2997 - val_loss: 1.5834\n",
      "Epoch 121/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2987 - val_loss: 1.5824\n",
      "Epoch 122/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2952 - val_loss: 1.5833\n",
      "Epoch 123/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2991 - val_loss: 1.5835\n",
      "Epoch 124/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3003 - val_loss: 1.5836\n",
      "Epoch 125/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2959 - val_loss: 1.5830\n",
      "Epoch 126/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3014 - val_loss: 1.5842\n",
      "Epoch 127/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2962 - val_loss: 1.5849\n",
      "Epoch 128/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3026 - val_loss: 1.5853\n",
      "Epoch 129/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2988 - val_loss: 1.5848\n",
      "Epoch 130/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2975 - val_loss: 1.5821\n",
      "Epoch 131/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2990 - val_loss: 1.5828\n",
      "Epoch 132/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2952 - val_loss: 1.5846\n",
      "Epoch 133/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2952 - val_loss: 1.5847\n",
      "Epoch 134/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2991 - val_loss: 1.5836\n",
      "Epoch 135/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2976 - val_loss: 1.5857\n",
      "Epoch 136/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2961 - val_loss: 1.5842\n",
      "Epoch 137/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2983 - val_loss: 1.5842\n",
      "Epoch 138/400\n",
      "3127/3127 [==============================] - 0s 40us/step - loss: 8.2974 - val_loss: 1.5860\n",
      "Epoch 139/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2971 - val_loss: 1.5854\n",
      "Epoch 140/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2967 - val_loss: 1.5824\n",
      "Epoch 141/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2980 - val_loss: 1.5846\n",
      "Epoch 142/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2942 - val_loss: 1.5834\n",
      "Epoch 143/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2986 - val_loss: 1.5848\n",
      "Epoch 144/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2967 - val_loss: 1.5855\n",
      "Epoch 145/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2963 - val_loss: 1.5846\n",
      "Epoch 146/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2980 - val_loss: 1.5862\n",
      "Epoch 147/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.3002 - val_loss: 1.5847\n",
      "Epoch 148/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2981 - val_loss: 1.5856\n",
      "Epoch 149/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.3019 - val_loss: 1.5847\n",
      "Epoch 150/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2980 - val_loss: 1.5824\n",
      "Epoch 151/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3002 - val_loss: 1.5848\n",
      "Epoch 152/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2947 - val_loss: 1.5837\n",
      "Epoch 153/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2984 - val_loss: 1.5846\n",
      "Epoch 154/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2988 - val_loss: 1.5841\n",
      "Epoch 155/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2974 - val_loss: 1.5851\n",
      "Epoch 156/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2968 - val_loss: 1.5849\n",
      "Epoch 157/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2992 - val_loss: 1.5839\n",
      "Epoch 158/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2963 - val_loss: 1.5828\n",
      "Epoch 159/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2998 - val_loss: 1.5836\n",
      "Epoch 160/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2966 - val_loss: 1.5828\n",
      "Epoch 161/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2942 - val_loss: 1.5853\n",
      "Epoch 162/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2998 - val_loss: 1.5844\n",
      "Epoch 163/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2986 - val_loss: 1.5837\n",
      "Epoch 164/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2957 - val_loss: 1.5834\n",
      "Epoch 165/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2973 - val_loss: 1.5852\n",
      "Epoch 166/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2978 - val_loss: 1.5854\n",
      "Epoch 167/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2970 - val_loss: 1.5847\n",
      "Epoch 168/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2961 - val_loss: 1.5843\n",
      "Epoch 169/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2941 - val_loss: 1.5847\n",
      "Epoch 170/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.3023 - val_loss: 1.5829\n",
      "Epoch 171/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2962 - val_loss: 1.5851\n",
      "Epoch 172/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2964 - val_loss: 1.5844\n",
      "Epoch 173/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2947 - val_loss: 1.5870\n",
      "Epoch 174/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2950 - val_loss: 1.5842\n",
      "Epoch 175/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2982 - val_loss: 1.5837\n",
      "Epoch 176/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2986 - val_loss: 1.5854\n",
      "Epoch 177/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2952 - val_loss: 1.5862\n",
      "Epoch 178/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2958 - val_loss: 1.5864\n",
      "Epoch 179/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2975 - val_loss: 1.5857\n",
      "Epoch 180/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2988 - val_loss: 1.5844\n",
      "Epoch 181/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3003 - val_loss: 1.5843\n",
      "Epoch 182/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2948 - val_loss: 1.5848\n",
      "Epoch 183/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2966 - val_loss: 1.5855\n",
      "Epoch 184/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2973 - val_loss: 1.5834\n",
      "Epoch 185/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2998 - val_loss: 1.5836\n",
      "Epoch 186/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2971 - val_loss: 1.5869\n",
      "Epoch 187/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2961 - val_loss: 1.5843\n",
      "Epoch 188/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2960 - val_loss: 1.5850\n",
      "Epoch 189/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2945 - val_loss: 1.5846\n",
      "Epoch 190/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2968 - val_loss: 1.5849\n",
      "Epoch 191/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2985 - val_loss: 1.5865\n",
      "Epoch 192/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2993 - val_loss: 1.5862\n",
      "Epoch 193/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2975 - val_loss: 1.5830\n",
      "Epoch 194/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.2953 - val_loss: 1.5846\n",
      "Epoch 195/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2971 - val_loss: 1.5868\n",
      "Epoch 196/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2980 - val_loss: 1.5868\n",
      "Epoch 197/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2962 - val_loss: 1.5866\n",
      "Epoch 198/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2965 - val_loss: 1.5853\n",
      "Epoch 199/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2934 - val_loss: 1.5850\n",
      "Epoch 200/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2959 - val_loss: 1.5842\n",
      "Epoch 201/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2945 - val_loss: 1.5858\n",
      "Epoch 202/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2975 - val_loss: 1.5872\n",
      "Epoch 203/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2988 - val_loss: 1.5863\n",
      "Epoch 204/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2958 - val_loss: 1.5868\n",
      "Epoch 205/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2977 - val_loss: 1.5845\n",
      "Epoch 206/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2945 - val_loss: 1.5877\n",
      "Epoch 207/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2967 - val_loss: 1.5862\n",
      "Epoch 208/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2917 - val_loss: 1.5864\n",
      "Epoch 209/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2938 - val_loss: 1.5858\n",
      "Epoch 210/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2985 - val_loss: 1.5847\n",
      "Epoch 211/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2957 - val_loss: 1.5861\n",
      "Epoch 212/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2927 - val_loss: 1.5860\n",
      "Epoch 213/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2975 - val_loss: 1.5869\n",
      "Epoch 214/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2925 - val_loss: 1.5858\n",
      "Epoch 215/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2958 - val_loss: 1.5850\n",
      "Epoch 216/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2916 - val_loss: 1.5854\n",
      "Epoch 217/400\n",
      "3127/3127 [==============================] - 0s 37us/step - loss: 8.2977 - val_loss: 1.5847\n",
      "Epoch 218/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2975 - val_loss: 1.5857\n",
      "Epoch 219/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2983 - val_loss: 1.5857\n",
      "Epoch 220/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3013 - val_loss: 1.5859\n",
      "Epoch 221/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2952 - val_loss: 1.5849\n",
      "Epoch 222/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2937 - val_loss: 1.5870\n",
      "Epoch 223/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2980 - val_loss: 1.5854\n",
      "Epoch 224/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2954 - val_loss: 1.5867\n",
      "Epoch 225/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2907 - val_loss: 1.5883\n",
      "Epoch 226/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2958 - val_loss: 1.5868\n",
      "Epoch 227/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2919 - val_loss: 1.5854\n",
      "Epoch 228/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2929 - val_loss: 1.5867\n",
      "Epoch 229/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2966 - val_loss: 1.5855\n",
      "Epoch 230/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2956 - val_loss: 1.5868\n",
      "Epoch 231/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2962 - val_loss: 1.5877\n",
      "Epoch 232/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.2921 - val_loss: 1.5861\n",
      "Epoch 233/400\n",
      "3127/3127 [==============================] - 0s 40us/step - loss: 8.2943 - val_loss: 1.5850\n",
      "Epoch 234/400\n",
      "3127/3127 [==============================] - 0s 38us/step - loss: 8.2939 - val_loss: 1.5865\n",
      "Epoch 235/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2957 - val_loss: 1.5862\n",
      "Epoch 236/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2925 - val_loss: 1.5872\n",
      "Epoch 237/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2939 - val_loss: 1.5846\n",
      "Epoch 238/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2918 - val_loss: 1.5848\n",
      "Epoch 239/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2974 - val_loss: 1.5854\n",
      "Epoch 240/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2949 - val_loss: 1.5858\n",
      "Epoch 241/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2949 - val_loss: 1.5882\n",
      "Epoch 242/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2950 - val_loss: 1.5869\n",
      "Epoch 243/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2968 - val_loss: 1.5873\n",
      "Epoch 244/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2960 - val_loss: 1.5856\n",
      "Epoch 245/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2980 - val_loss: 1.5864\n",
      "Epoch 246/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2932 - val_loss: 1.5858\n",
      "Epoch 247/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2965 - val_loss: 1.5858\n",
      "Epoch 248/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2961 - val_loss: 1.5862\n",
      "Epoch 249/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2969 - val_loss: 1.5872\n",
      "Epoch 250/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2988 - val_loss: 1.5870\n",
      "Epoch 251/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3008 - val_loss: 1.5870\n",
      "Epoch 252/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2900 - val_loss: 1.5874\n",
      "Epoch 253/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2938 - val_loss: 1.5854\n",
      "Epoch 254/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2941 - val_loss: 1.5859\n",
      "Epoch 255/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2941 - val_loss: 1.5858\n",
      "Epoch 256/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2946 - val_loss: 1.5852\n",
      "Epoch 257/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.3005 - val_loss: 1.5871\n",
      "Epoch 258/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2957 - val_loss: 1.5864\n",
      "Epoch 259/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2983 - val_loss: 1.5877\n",
      "Epoch 260/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2966 - val_loss: 1.5876\n",
      "Epoch 261/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2910 - val_loss: 1.5887\n",
      "Epoch 262/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2982 - val_loss: 1.5877\n",
      "Epoch 263/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2918 - val_loss: 1.5870\n",
      "Epoch 264/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2929 - val_loss: 1.5880\n",
      "Epoch 265/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2973 - val_loss: 1.5862\n",
      "Epoch 266/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2940 - val_loss: 1.5887\n",
      "Epoch 267/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2943 - val_loss: 1.5861\n",
      "Epoch 268/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2962 - val_loss: 1.5870\n",
      "Epoch 269/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2911 - val_loss: 1.5861\n",
      "Epoch 270/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2941 - val_loss: 1.5901\n",
      "Epoch 271/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2935 - val_loss: 1.5882\n",
      "Epoch 272/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2939 - val_loss: 1.5874\n",
      "Epoch 273/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2955 - val_loss: 1.5870\n",
      "Epoch 274/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2960 - val_loss: 1.5889\n",
      "Epoch 275/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2910 - val_loss: 1.5872\n",
      "Epoch 276/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2911 - val_loss: 1.5844\n",
      "Epoch 277/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2930 - val_loss: 1.5884\n",
      "Epoch 278/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2960 - val_loss: 1.5861\n",
      "Epoch 279/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2938 - val_loss: 1.5888\n",
      "Epoch 280/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2936 - val_loss: 1.5859\n",
      "Epoch 281/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2982 - val_loss: 1.5882\n",
      "Epoch 282/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2958 - val_loss: 1.5874\n",
      "Epoch 283/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2973 - val_loss: 1.5863\n",
      "Epoch 284/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2968 - val_loss: 1.5875\n",
      "Epoch 285/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2912 - val_loss: 1.5862\n",
      "Epoch 286/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2961 - val_loss: 1.5894\n",
      "Epoch 287/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2937 - val_loss: 1.5881\n",
      "Epoch 288/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2967 - val_loss: 1.5875\n",
      "Epoch 289/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2944 - val_loss: 1.5871\n",
      "Epoch 290/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2984 - val_loss: 1.5877\n",
      "Epoch 291/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2937 - val_loss: 1.5853\n",
      "Epoch 292/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2931 - val_loss: 1.5865\n",
      "Epoch 293/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2929 - val_loss: 1.5880\n",
      "Epoch 294/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2935 - val_loss: 1.5872\n",
      "Epoch 295/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2954 - val_loss: 1.5863\n",
      "Epoch 296/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2933 - val_loss: 1.5880\n",
      "Epoch 297/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2980 - val_loss: 1.5872\n",
      "Epoch 298/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2927 - val_loss: 1.5877\n",
      "Epoch 299/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2954 - val_loss: 1.5890\n",
      "Epoch 300/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2946 - val_loss: 1.5899\n",
      "Epoch 301/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2946 - val_loss: 1.5883\n",
      "Epoch 302/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2950 - val_loss: 1.5879\n",
      "Epoch 303/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2929 - val_loss: 1.5882\n",
      "Epoch 304/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2918 - val_loss: 1.5861\n",
      "Epoch 305/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2945 - val_loss: 1.5883\n",
      "Epoch 306/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2932 - val_loss: 1.5886\n",
      "Epoch 307/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2965 - val_loss: 1.5888\n",
      "Epoch 308/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2946 - val_loss: 1.5872\n",
      "Epoch 309/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2947 - val_loss: 1.5877\n",
      "Epoch 310/400\n",
      "3127/3127 [==============================] - 0s 37us/step - loss: 8.2934 - val_loss: 1.5879\n",
      "Epoch 311/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2947 - val_loss: 1.5871\n",
      "Epoch 312/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2931 - val_loss: 1.5879\n",
      "Epoch 313/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2914 - val_loss: 1.5897\n",
      "Epoch 314/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2948 - val_loss: 1.5889\n",
      "Epoch 315/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2919 - val_loss: 1.5905\n",
      "Epoch 316/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2943 - val_loss: 1.5875\n",
      "Epoch 317/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2940 - val_loss: 1.5881\n",
      "Epoch 318/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2944 - val_loss: 1.5889\n",
      "Epoch 319/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2914 - val_loss: 1.5884\n",
      "Epoch 320/400\n",
      "3127/3127 [==============================] - 0s 33us/step - loss: 8.2947 - val_loss: 1.5886\n",
      "Epoch 321/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2949 - val_loss: 1.5907\n",
      "Epoch 322/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2925 - val_loss: 1.5896\n",
      "Epoch 323/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2933 - val_loss: 1.5897\n",
      "Epoch 324/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2960 - val_loss: 1.5893\n",
      "Epoch 325/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2967 - val_loss: 1.5916\n",
      "Epoch 326/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2951 - val_loss: 1.5888\n",
      "Epoch 327/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2937 - val_loss: 1.5888\n",
      "Epoch 328/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2948 - val_loss: 1.5882\n",
      "Epoch 329/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2953 - val_loss: 1.5895\n",
      "Epoch 330/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2910 - val_loss: 1.5883\n",
      "Epoch 331/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2958 - val_loss: 1.5895\n",
      "Epoch 332/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2963 - val_loss: 1.5889\n",
      "Epoch 333/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2922 - val_loss: 1.5887\n",
      "Epoch 334/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2957 - val_loss: 1.5888\n",
      "Epoch 335/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2911 - val_loss: 1.5889\n",
      "Epoch 336/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2934 - val_loss: 1.5897\n",
      "Epoch 337/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2908 - val_loss: 1.5893\n",
      "Epoch 338/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2948 - val_loss: 1.5887\n",
      "Epoch 339/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2931 - val_loss: 1.5893\n",
      "Epoch 340/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2929 - val_loss: 1.5891\n",
      "Epoch 341/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2927 - val_loss: 1.5892\n",
      "Epoch 342/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2935 - val_loss: 1.5893\n",
      "Epoch 343/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2967 - val_loss: 1.5919\n",
      "Epoch 344/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.2949 - val_loss: 1.5906\n",
      "Epoch 345/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2958 - val_loss: 1.5896\n",
      "Epoch 346/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2953 - val_loss: 1.5895\n",
      "Epoch 347/400\n",
      "3127/3127 [==============================] - 0s 36us/step - loss: 8.2925 - val_loss: 1.5879\n",
      "Epoch 348/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2929 - val_loss: 1.5898\n",
      "Epoch 349/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2925 - val_loss: 1.5874\n",
      "Epoch 350/400\n",
      "3127/3127 [==============================] - 0s 34us/step - loss: 8.2934 - val_loss: 1.5890\n",
      "Epoch 351/400\n",
      "3127/3127 [==============================] - 0s 38us/step - loss: 8.2929 - val_loss: 1.5887\n",
      "Epoch 352/400\n",
      "3127/3127 [==============================] - 0s 37us/step - loss: 8.2945 - val_loss: 1.5884\n",
      "Epoch 353/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2926 - val_loss: 1.5886\n",
      "Epoch 354/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2949 - val_loss: 1.5878\n",
      "Epoch 355/400\n",
      "3127/3127 [==============================] - 0s 35us/step - loss: 8.2921 - val_loss: 1.5875\n",
      "Epoch 356/400\n",
      "1472/3127 [=============>................] - ETA: 0s - loss: 11.2619"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5043cf33394e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=400, batch_size=64, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3909, 2)\n"
     ]
    }
   ],
   "source": [
    "Yhat = model.predict(X_train)\n",
    "print(Yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: 4.652412\n",
      "Profit: 5.694292\n",
      "Profit: 7.211534\n",
      "Profit: 8.243018\n",
      "Profit: 8.484082\n",
      "Profit: 9.236345\n",
      "Profit: 12.810128\n",
      "Profit: 12.843750\n",
      "Profit: 12.872384\n",
      "Profit: 13.848197\n",
      "Profit: 21.345348\n",
      "Profit: 22.209487\n",
      "Profit: 23.577464\n",
      "Profit: 26.297471\n",
      "Profit: 29.748967\n",
      "Profit: 30.291923\n",
      "Profit: 30.914850\n",
      "Profit: 31.380695\n",
      "Profit: 31.955702\n",
      "Profit: 31.998556\n",
      "Profit: 32.548152\n",
      "Profit: 33.963973\n",
      "Profit: 34.385449\n",
      "Profit: 34.749446\n",
      "Profit: 36.261260\n",
      "Profit: 36.618742\n",
      "Profit: 36.804478\n",
      "Profit: 37.304249\n",
      "Profit: 39.197551\n",
      "Profit: 39.279822\n",
      "Profit: 39.486831\n",
      "Profit: 39.551043\n",
      "Profit: 40.200086\n",
      "Profit: 40.392937\n",
      "Profit: 41.488677\n",
      "Profit: 41.675298\n",
      "Profit: 42.724980\n",
      "Profit: 43.979160\n",
      "Profit: 44.838851\n",
      "Profit: 45.661762\n",
      "Profit: 45.765486\n",
      "Profit: 46.024674\n",
      "Profit: 46.783524\n",
      "Profit: 47.864015\n",
      "Profit: 48.982568\n",
      "Profit: 49.240613\n",
      "Profit: 49.569544\n",
      "Profit: 50.016527\n",
      "Profit: 50.438326\n",
      "Profit: 51.113930\n",
      "Profit: 52.386119\n",
      "Profit: 52.568556\n",
      "Profit: 53.252188\n",
      "Profit: 53.769148\n",
      "Profit: 54.012442\n",
      "Profit: 55.107380\n",
      "Profit: 56.464660\n",
      "Profit: 58.481887\n",
      "Profit: 58.534852\n",
      "Profit: 58.632260\n",
      "Profit: 59.624962\n",
      "Profit: 60.163770\n",
      "Profit: 61.940299\n",
      "Profit: 62.401045\n",
      "Profit: 62.978264\n",
      "Profit: 63.534720\n",
      "Profit: 69.775574\n",
      "Profit: 70.465337\n"
     ]
    }
   ],
   "source": [
    "buy = True\n",
    "capital = 1000\n",
    "usd = capital\n",
    "stock = 0\n",
    "profit = []\n",
    "threshold = 3\n",
    "for i, x in enumerate(Y):\n",
    "    buy_dist, sell_dist = Yhat[i]\n",
    "    if abs(buy_dist) < threshold and buy:\n",
    "        stock = usd / x\n",
    "        usd = 0\n",
    "        buy = False\n",
    "    elif abs(sell_dist) < threshold and not buy:\n",
    "        n_usd = stock * x\n",
    "        if len(profit) > 0 and n_usd - capital < profit[-1]:\n",
    "            continue\n",
    "        usd = n_usd\n",
    "        stock = 0\n",
    "        buy = True\n",
    "        profit.append(usd - capital)\n",
    "        print(\"Profit: %f\" % profit[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final profit: $70.47\n"
     ]
    }
   ],
   "source": [
    "print(\"Final profit: $%.02f\" % profit[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('AMZN-1.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
